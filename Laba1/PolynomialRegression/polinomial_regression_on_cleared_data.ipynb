{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импорт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import joblib\n",
    "# omsky_gamedev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка датасета для регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Appliances</th>\n",
       "      <th>lights</th>\n",
       "      <th>T1</th>\n",
       "      <th>RH_1</th>\n",
       "      <th>T2</th>\n",
       "      <th>RH_2</th>\n",
       "      <th>T3</th>\n",
       "      <th>RH_3</th>\n",
       "      <th>T4</th>\n",
       "      <th>RH_4</th>\n",
       "      <th>...</th>\n",
       "      <th>T_out</th>\n",
       "      <th>Press_mm_hg</th>\n",
       "      <th>RH_out</th>\n",
       "      <th>Windspeed</th>\n",
       "      <th>Visibility</th>\n",
       "      <th>Tdewpoint</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>19.890000</td>\n",
       "      <td>47.596667</td>\n",
       "      <td>19.200000</td>\n",
       "      <td>44.790000</td>\n",
       "      <td>19.790000</td>\n",
       "      <td>44.730000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>45.566667</td>\n",
       "      <td>...</td>\n",
       "      <td>6.60</td>\n",
       "      <td>733.5</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>5.3</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>19.890000</td>\n",
       "      <td>46.693333</td>\n",
       "      <td>19.200000</td>\n",
       "      <td>44.722500</td>\n",
       "      <td>19.790000</td>\n",
       "      <td>44.790000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>45.992500</td>\n",
       "      <td>...</td>\n",
       "      <td>6.48</td>\n",
       "      <td>733.6</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>59.166667</td>\n",
       "      <td>5.2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>1030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>19.890000</td>\n",
       "      <td>46.300000</td>\n",
       "      <td>19.200000</td>\n",
       "      <td>44.626667</td>\n",
       "      <td>19.790000</td>\n",
       "      <td>44.933333</td>\n",
       "      <td>18.926667</td>\n",
       "      <td>45.890000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.37</td>\n",
       "      <td>733.7</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>55.333333</td>\n",
       "      <td>5.1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>1040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "      <td>19.890000</td>\n",
       "      <td>46.066667</td>\n",
       "      <td>19.200000</td>\n",
       "      <td>44.590000</td>\n",
       "      <td>19.790000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>18.890000</td>\n",
       "      <td>45.723333</td>\n",
       "      <td>...</td>\n",
       "      <td>6.25</td>\n",
       "      <td>733.8</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>51.500000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>19.890000</td>\n",
       "      <td>46.333333</td>\n",
       "      <td>19.200000</td>\n",
       "      <td>44.530000</td>\n",
       "      <td>19.790000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>18.890000</td>\n",
       "      <td>45.530000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.13</td>\n",
       "      <td>733.9</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>47.666667</td>\n",
       "      <td>4.9</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>1060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18533</th>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>25.566667</td>\n",
       "      <td>46.560000</td>\n",
       "      <td>25.890000</td>\n",
       "      <td>42.025714</td>\n",
       "      <td>27.200000</td>\n",
       "      <td>41.163333</td>\n",
       "      <td>24.700000</td>\n",
       "      <td>45.590000</td>\n",
       "      <td>...</td>\n",
       "      <td>22.70</td>\n",
       "      <td>755.2</td>\n",
       "      <td>55.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>23.666667</td>\n",
       "      <td>13.3</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>1040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18534</th>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>46.500000</td>\n",
       "      <td>25.754000</td>\n",
       "      <td>42.080000</td>\n",
       "      <td>27.133333</td>\n",
       "      <td>41.223333</td>\n",
       "      <td>24.700000</td>\n",
       "      <td>45.590000</td>\n",
       "      <td>...</td>\n",
       "      <td>22.60</td>\n",
       "      <td>755.2</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>24.500000</td>\n",
       "      <td>13.3</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18535</th>\n",
       "      <td>270</td>\n",
       "      <td>10</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>46.596667</td>\n",
       "      <td>25.628571</td>\n",
       "      <td>42.768571</td>\n",
       "      <td>27.050000</td>\n",
       "      <td>41.690000</td>\n",
       "      <td>24.700000</td>\n",
       "      <td>45.730000</td>\n",
       "      <td>...</td>\n",
       "      <td>22.50</td>\n",
       "      <td>755.2</td>\n",
       "      <td>56.333333</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>25.333333</td>\n",
       "      <td>13.3</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>1060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18536</th>\n",
       "      <td>420</td>\n",
       "      <td>10</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>46.990000</td>\n",
       "      <td>25.414000</td>\n",
       "      <td>43.036000</td>\n",
       "      <td>26.890000</td>\n",
       "      <td>41.290000</td>\n",
       "      <td>24.700000</td>\n",
       "      <td>45.790000</td>\n",
       "      <td>...</td>\n",
       "      <td>22.30</td>\n",
       "      <td>755.2</td>\n",
       "      <td>56.666667</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>26.166667</td>\n",
       "      <td>13.2</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>1070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18537</th>\n",
       "      <td>430</td>\n",
       "      <td>10</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>46.600000</td>\n",
       "      <td>25.264286</td>\n",
       "      <td>42.971429</td>\n",
       "      <td>26.823333</td>\n",
       "      <td>41.156667</td>\n",
       "      <td>24.700000</td>\n",
       "      <td>45.963333</td>\n",
       "      <td>...</td>\n",
       "      <td>22.20</td>\n",
       "      <td>755.2</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>13.2</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18538 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Appliances  lights         T1       RH_1         T2       RH_2  \\\n",
       "0              60      30  19.890000  47.596667  19.200000  44.790000   \n",
       "1              60      30  19.890000  46.693333  19.200000  44.722500   \n",
       "2              50      30  19.890000  46.300000  19.200000  44.626667   \n",
       "3              50      40  19.890000  46.066667  19.200000  44.590000   \n",
       "4              60      40  19.890000  46.333333  19.200000  44.530000   \n",
       "...           ...     ...        ...        ...        ...        ...   \n",
       "18533         100       0  25.566667  46.560000  25.890000  42.025714   \n",
       "18534          90       0  25.500000  46.500000  25.754000  42.080000   \n",
       "18535         270      10  25.500000  46.596667  25.628571  42.768571   \n",
       "18536         420      10  25.500000  46.990000  25.414000  43.036000   \n",
       "18537         430      10  25.500000  46.600000  25.264286  42.971429   \n",
       "\n",
       "              T3       RH_3         T4       RH_4  ...  T_out  Press_mm_hg  \\\n",
       "0      19.790000  44.730000  19.000000  45.566667  ...   6.60        733.5   \n",
       "1      19.790000  44.790000  19.000000  45.992500  ...   6.48        733.6   \n",
       "2      19.790000  44.933333  18.926667  45.890000  ...   6.37        733.7   \n",
       "3      19.790000  45.000000  18.890000  45.723333  ...   6.25        733.8   \n",
       "4      19.790000  45.000000  18.890000  45.530000  ...   6.13        733.9   \n",
       "...          ...        ...        ...        ...  ...    ...          ...   \n",
       "18533  27.200000  41.163333  24.700000  45.590000  ...  22.70        755.2   \n",
       "18534  27.133333  41.223333  24.700000  45.590000  ...  22.60        755.2   \n",
       "18535  27.050000  41.690000  24.700000  45.730000  ...  22.50        755.2   \n",
       "18536  26.890000  41.290000  24.700000  45.790000  ...  22.30        755.2   \n",
       "18537  26.823333  41.156667  24.700000  45.963333  ...  22.20        755.2   \n",
       "\n",
       "          RH_out  Windspeed  Visibility  Tdewpoint  day  month  year  time  \n",
       "0      92.000000   7.000000   63.000000        5.3   11      1  2016  1020  \n",
       "1      92.000000   6.666667   59.166667        5.2   11      1  2016  1030  \n",
       "2      92.000000   6.333333   55.333333        5.1   11      1  2016  1040  \n",
       "3      92.000000   6.000000   51.500000        5.0   11      1  2016  1050  \n",
       "4      92.000000   5.666667   47.666667        4.9   11      1  2016  1060  \n",
       "...          ...        ...         ...        ...  ...    ...   ...   ...  \n",
       "18533  55.666667   3.333333   23.666667       13.3   27      5  2016  1040  \n",
       "18534  56.000000   3.500000   24.500000       13.3   27      5  2016  1050  \n",
       "18535  56.333333   3.666667   25.333333       13.3   27      5  2016  1060  \n",
       "18536  56.666667   3.833333   26.166667       13.2   27      5  2016  1070  \n",
       "18537  57.000000   4.000000   27.000000       13.2   27      5  2016  1080  \n",
       "\n",
       "[18538 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = pd.read_csv('../../Data/energy_task_moded_removed_nan.csv')\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Разбиваем на выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(models.drop('Appliances', axis=1), models['Appliances'], test_size=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>Полиномиальная регрессия</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "power = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обычная полиномиальная регрессия (без гиппер параметра)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 50.29429676762403\n",
      "RMSE: 7093.339593868581\n",
      "MSE: 84.22196621944052\n",
      "MAPE: 1.1306598259551703\n",
      "R^2: 0.29975803700550785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-9.69557585e-10, -4.55827594e-06,  4.72720937e-04,  5.03407332e-05,\n",
       "       -5.10071632e-05,  3.80224400e-06, -1.34889912e-04,  1.54367352e-04,\n",
       "       -1.62903149e-05, -4.63839817e-05,  1.73187206e-04, -3.23473273e-06,\n",
       "        1.26024437e-04,  1.88619147e-05, -7.13952683e-04,  4.04629977e-05,\n",
       "        9.57451974e-05, -1.03274776e-04,  9.92144548e-05,  5.99542142e-05,\n",
       "        1.14940658e-04,  4.61189333e-06,  2.14455874e-05, -3.18027269e-05,\n",
       "       -2.93934434e-06, -2.84054451e-04,  4.40665429e-05,  6.60961828e-04,\n",
       "        2.88848620e-10, -2.59592841e-07, -4.90579251e-02, -1.76184643e-01,\n",
       "        1.55273667e-01, -8.01887551e-01, -4.55644570e-01,  3.03662732e-01,\n",
       "        3.03213196e-02, -3.64693606e-01,  5.86833174e-02,  3.95706269e-01,\n",
       "       -1.93451060e-02,  3.95127177e-01,  8.35427832e-03,  1.07548878e+00,\n",
       "        1.55586414e-01, -4.64934375e-01, -4.17906964e-02, -6.43454334e-01,\n",
       "        1.00820825e-01, -7.90085385e-01,  6.28667934e-02, -1.22993731e-01,\n",
       "       -7.57778036e-03,  2.94537485e-02,  5.11866101e-01,  4.36230246e-02,\n",
       "       -6.93739738e-01, -9.24812441e-03,  6.98951260e-04, -1.28354360e+01,\n",
       "       -1.71815359e+01, -5.50792764e-01, -1.33935295e+00,  2.90499491e+01,\n",
       "       -5.96448106e+00,  1.23071402e+01,  1.57546509e+01,  1.90405441e+00,\n",
       "       -9.34240544e-01, -8.98089052e+00,  1.34991273e-01, -2.02857612e+00,\n",
       "        5.80024939e+00, -4.21363191e+00, -5.29862762e+00, -1.21845260e+01,\n",
       "       -3.44344378e+00, -1.23750757e+01, -1.01374312e+00, -5.38851245e+00,\n",
       "       -5.37058538e+00, -4.70447889e-01,  2.63741411e+01, -1.21077863e+00,\n",
       "       -1.22443619e+01,  9.52930432e-01, -9.51375973e-03, -1.20400342e+00,\n",
       "        3.94003066e-01, -2.25694993e+00,  6.56303752e+00,  1.12606869e+00,\n",
       "        9.01720125e+00,  1.68521656e+00, -1.31431114e+00, -6.73546407e-01,\n",
       "       -2.82935731e+00, -3.24885731e-01, -3.27837855e+00,  1.25314598e+00,\n",
       "        9.22508508e-01, -2.27451042e-01,  5.86641571e+00, -7.29702044e-01,\n",
       "        1.81615290e+00, -9.49706792e-02,  2.71114650e-01, -2.56650912e-01,\n",
       "       -1.43366370e-01,  1.26559684e+00, -1.33231715e-01, -8.29288222e+00,\n",
       "        1.01512527e-01,  1.91013339e-02,  4.04987122e+00,  7.66497314e+00,\n",
       "       -5.40299307e+00, -3.35665609e+00, -1.26924496e+01, -8.87555236e+00,\n",
       "        2.34037196e+00,  2.00678713e+00,  9.12964741e-01,  4.81161528e-01,\n",
       "        1.29902505e+01, -2.03013234e+00, -5.65505805e+00,  7.72371829e+00,\n",
       "        9.46668757e+00, -1.51007725e+00,  4.77934182e+00, -2.56849799e-01,\n",
       "        1.18329282e+00, -9.04514871e-02,  3.82144406e-01, -4.76351359e+00,\n",
       "       -2.87845536e-01, -1.24756675e+01, -1.02827183e-01, -2.20442636e-03,\n",
       "        3.51473812e+00,  3.32866179e-01, -3.70445886e+00, -1.06236250e+01,\n",
       "       -2.30895927e+00, -6.99112371e-01,  9.19427998e-01, -3.35352791e-02,\n",
       "        5.67296974e-01,  7.44038091e+00, -6.29210715e-01,  3.25842367e-01,\n",
       "        1.85989719e+00, -8.13203417e-01,  2.14087374e-02, -6.56088581e-01,\n",
       "       -1.23159493e-01, -9.38567000e-01, -8.77239501e-01,  8.07677313e-02,\n",
       "        7.69677514e-01, -3.89825684e-01,  6.03051089e+00,  7.66804600e-03,\n",
       "       -1.02010727e-02, -1.42199499e+01,  1.64307047e+00, -1.12321790e+01,\n",
       "       -1.18097787e+01, -1.47869203e+01, -3.29357505e-01,  9.32550903e+00,\n",
       "        1.32325273e-02,  1.26531878e+01,  1.54576210e+00,  1.62326212e+00,\n",
       "        2.37520317e+00,  1.63266985e+01, -1.38210874e+00, -1.10853644e+01,\n",
       "        9.65051668e-01, -1.32596946e+00,  2.24686178e+00,  1.42201459e-01,\n",
       "        6.65754581e+00, -1.13019470e+00, -3.66912856e+00, -2.71939536e-01,\n",
       "        1.22288040e-04,  3.54267038e+00,  3.60690907e+00,  2.00716558e-02,\n",
       "        2.77229975e+00,  4.16633082e-01,  7.99106517e-01,  1.78977426e-01,\n",
       "        4.60557806e-01, -1.15326374e+00, -4.33889246e-02, -1.13062583e+00,\n",
       "       -5.12020708e+00,  3.82152681e-02, -8.09571717e+00, -6.85657800e-01,\n",
       "       -1.51907743e+00,  1.47297012e+00, -6.39473779e-02,  6.70419527e+00,\n",
       "        6.82959301e-01,  1.19667788e+01,  3.11207379e-01, -2.78515407e-03,\n",
       "        2.08327853e+00,  3.66183627e+00, -8.46026564e+00, -5.12336704e-01,\n",
       "        5.49212439e-01,  1.74164230e-01, -5.87555516e+00, -3.29536827e+00,\n",
       "        1.32304656e+01,  9.06448901e-01, -2.24392797e-01,  4.46537214e+00,\n",
       "       -1.06244009e+01,  4.86191344e-03, -1.65546693e+00,  4.82885329e-01,\n",
       "       -9.67150653e-02,  6.82594144e+00,  8.93095464e-01,  2.26248147e+01,\n",
       "       -3.28421721e-02,  2.98452779e-04,  1.53150663e+00,  5.62745701e+00,\n",
       "       -4.79070117e-01,  8.08960092e-01, -3.11186854e-01, -1.49649031e+00,\n",
       "       -1.90664643e+00,  2.77382376e+00,  6.61121199e-01, -6.28455817e+00,\n",
       "        2.55466905e+00,  5.59545075e+00, -1.15918033e-01,  1.51362208e+00,\n",
       "        1.09883234e+00,  9.38995003e-02, -7.79276830e+00,  5.73519817e-01,\n",
       "        1.15243754e+00, -9.35094469e-02, -1.93935432e-03,  8.62712379e+00,\n",
       "       -1.04350147e+00,  1.80678466e+00, -9.61633460e-02, -5.15321392e+00,\n",
       "       -2.77597947e+00,  5.93831026e-01, -2.67961292e+00, -4.50292082e+00,\n",
       "        1.19293452e-01, -1.13197248e+01, -4.12768446e-01, -1.81950513e+00,\n",
       "       -1.08664788e+00,  1.28985017e-01,  1.15322502e+01,  7.98408643e-01,\n",
       "        1.48635502e+01,  3.49147083e-01, -1.07016024e-02,  6.45825407e-02,\n",
       "       -2.80372102e-01,  1.32282402e-02,  4.64050418e-01, -3.40468024e-02,\n",
       "       -7.08362823e-01, -2.94050238e-02,  7.78187931e-01, -1.32128824e-01,\n",
       "       -9.21281390e-02,  2.56916658e-02, -6.98222253e-02,  3.44277793e-02,\n",
       "       -2.42300648e-02,  4.54610747e-01,  5.93871871e-02,  8.30424684e-01,\n",
       "       -6.52347080e-03, -9.39208815e-04, -1.65990914e+00, -6.35634098e-02,\n",
       "       -7.52272542e+00,  1.83781570e+00,  5.57770733e-01,  3.61039336e-01,\n",
       "       -3.31894135e+00, -1.18902545e-01,  5.08517062e-01, -4.65848805e-01,\n",
       "       -6.61866631e-01, -1.73331829e+00, -2.88958522e-02,  2.00250226e+00,\n",
       "       -3.09139103e-01,  1.13154995e+01,  2.54067256e-01,  6.17145541e-03,\n",
       "        1.72530087e-02, -2.03510391e+00, -5.05267300e-02,  1.77172764e-02,\n",
       "       -1.94224045e-02,  1.66252482e+00, -1.82048662e-01, -1.53225638e-01,\n",
       "       -9.09622957e-02, -1.13239198e-01, -2.54589328e-01, -1.50862983e-02,\n",
       "        3.87873177e-01, -5.16350865e-03, -3.89385982e-01,  3.80219111e-02,\n",
       "        1.48182034e-04, -4.15636036e+00, -4.15498172e+00, -5.47571768e+00,\n",
       "        4.60696770e+00,  2.45492744e+01, -4.88064363e+00,  3.69435477e+01,\n",
       "        2.61025174e+00,  8.11430696e+00,  3.33445918e+00,  3.65643914e-01,\n",
       "       -2.82845625e+01, -1.18286312e+00, -6.29514073e+01, -1.43933169e+00,\n",
       "       -6.71229896e-03, -2.91359330e-01,  2.60146993e-02, -2.75364197e-02,\n",
       "        3.53342213e+00,  1.37001011e+00,  1.09454602e+00, -1.88336933e-01,\n",
       "        6.18478310e-01, -2.98850142e-01,  2.00338479e-03, -2.86084038e+00,\n",
       "       -9.90307500e-02,  1.62362091e-01,  8.15786902e-02,  3.51454521e-04,\n",
       "       -1.44895138e+00, -2.86810693e+00, -8.14251359e+00,  2.90090113e+00,\n",
       "       -1.33457465e-02, -4.41087711e-01,  3.93856887e-02, -1.26986732e-01,\n",
       "        1.47287215e-01, -4.51687340e+00, -8.27585417e-01,  1.92090965e+01,\n",
       "        1.93020979e-01,  2.10782664e-02, -9.66026435e-02, -7.79404135e-01,\n",
       "       -1.12827629e+00,  6.63081960e-01,  4.74231662e-01,  2.18822736e-01,\n",
       "       -1.30284384e+00,  3.94265128e-02, -1.42128968e+00, -2.90969505e-01,\n",
       "       -4.39497093e+00, -2.08200827e-01, -7.10063162e-05, -6.32969880e+00,\n",
       "       -4.16814532e+00,  2.04877306e+00, -6.06750512e-01, -8.29403401e-01,\n",
       "        2.10543655e+00, -2.29823410e-01, -2.59457954e+00,  1.18544093e+00,\n",
       "        1.19129511e+01,  2.00018517e-01,  9.13816692e-03, -4.23248076e-01,\n",
       "       -3.75555975e+00, -7.47119871e-02, -7.66491683e-01,  2.59457030e-01,\n",
       "       -6.39910473e-02,  3.75164716e+00,  2.66482939e-01,  6.50307687e+00,\n",
       "        1.20868151e-01,  1.41840559e-03, -1.18758618e+00, -2.60256409e-01,\n",
       "       -2.93690180e-01,  9.56036549e-02, -1.00161242e-01,  2.53685479e+00,\n",
       "        5.38324723e-01, -9.14885868e-01,  2.31719290e-01, -1.08640543e-02,\n",
       "        6.58231262e-03,  1.02590189e-02,  2.13203241e-01,  1.28759797e-02,\n",
       "        9.39465106e-01, -2.31765148e-01, -3.69979724e+00,  9.29675370e-03,\n",
       "        1.65328492e-03, -5.90665670e-02, -4.57430438e-02,  1.35248136e-02,\n",
       "        1.18097037e+00,  6.89861162e-02,  2.76361561e-01,  4.32339645e-02,\n",
       "       -2.00431436e-03, -5.40939241e-01,  7.67030651e-02,  2.62903644e+00,\n",
       "       -3.74061864e-01, -8.81647331e+00, -6.41149670e-02, -3.93316592e-03,\n",
       "       -4.25976674e-03,  8.43091823e-02,  1.28168801e-04, -3.97117857e-01,\n",
       "       -5.92458349e-03, -1.99587441e-05, -2.53742007e+00, -4.26118895e-01,\n",
       "       -8.86488111e+00, -5.72652714e-01,  1.61104124e-03,  6.17529449e-02,\n",
       "        2.17490969e+00,  8.88401332e-02, -1.97809803e-04, -2.16482027e+00,\n",
       "        1.33249753e+00, -9.39147644e-03,  0.00000000e+00, -5.24611225e-04,\n",
       "       -1.35246456e-04])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polynomial_regression_classic = LinearRegression().fit(PolynomialFeatures(power).fit_transform(X_train), y_train)\n",
    "y_predicted = polynomial_regression_classic.predict(PolynomialFeatures(power).fit_transform(X_test))\n",
    "polynomial_regression_classic_errors = {'MAE': mean_absolute_error(y_predicted, y_test),\n",
    "                                        'RMSE': mean_squared_error(y_predicted, y_test),\n",
    "                                        'MSE': mean_squared_error(y_predicted, y_test)**0.5,\n",
    "                                        'MAPE': mean_absolute_percentage_error(y_predicted, y_test),\n",
    "                                        'R^2': polynomial_regression_classic.score(PolynomialFeatures(power).fit_transform(X_test), y_test)}\n",
    "print(f\"MAE: {mean_absolute_error(y_predicted, y_test)}\",\n",
    "      f'RMSE: {mean_squared_error(y_predicted, y_test)}',\n",
    "      f'MSE: {mean_squared_error(y_predicted, y_test)**0.5}',\n",
    "      f'MAPE: {mean_absolute_percentage_error(y_predicted, y_test)}',\n",
    "      f'R^2: {polynomial_regression_classic.score(PolynomialFeatures(power).fit_transform(X_test), y_test)}',\n",
    "      sep='\\n')\n",
    "polynomial_regression_classic.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge (Полиномиальная регрессия + L1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge (полиномиальная регрессия) - подборка гиппер параметра $\\alpha$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.59467e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.46852e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.50762e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.52263e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.43332e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 2}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_optimal_for_polynomial_regression = GridSearchCV(Ridge(), {'alpha': np.arange(1, 3, 1)}).fit(PolynomialFeatures(power).fit_transform(X_train), y_train)\n",
    "ridge_optimal_for_polynomial_regression.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.59467e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.46852e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.50762e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.52263e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.43332e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.59467e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.46852e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.50762e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.52263e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.43332e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.59467e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.46852e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.50762e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.52263e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.43332e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.59467e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.46852e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.50762e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.52263e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.43332e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.59467e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.46852e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.50762e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.52263e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.43332e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 2}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 10\n",
    "a = 0\n",
    "b = 1000\n",
    "while i > 0.0001:\n",
    "    ridge_optimal_for_polynomial_regression = GridSearchCV(Ridge(), {'alpha': np.arange(1, 3, 1)}).fit(PolynomialFeatures(power).fit_transform(X_train), y_train)\n",
    "    if (ridge_optimal_for_polynomial_regression.best_params_['alpha'] == 0):\n",
    "        break\n",
    "    elif (ridge_optimal_for_polynomial_regression.best_params_['alpha'] != b):\n",
    "        a = ridge_optimal_for_polynomial_regression.best_params_['alpha']-i\n",
    "        b = ridge_optimal_for_polynomial_regression.best_params_['alpha']+i\n",
    "        i/=10\n",
    "    else:\n",
    "        a = b\n",
    "        b*=2\n",
    "\n",
    "ridge_optimal_for_polynomial_regression.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge (полиномиальная регрессия) - обучение с подобранным гиппер параметрам $\\alpha$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 50.26523083587469\n",
      "RMSE: 7090.927261304732\n",
      "MSE: 84.20764372255486\n",
      "MAPE: 1.4525536008632973\n",
      "R^2: 0.2999961782177748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00, -4.66625359e-06,  4.65729906e-04,  4.95279064e-05,\n",
       "       -4.71194350e-05,  4.62622532e-06, -1.32599467e-04,  1.53889001e-04,\n",
       "       -1.69727118e-05, -4.56263899e-05,  1.69629991e-04, -3.24760167e-06,\n",
       "        1.26287194e-04,  1.94816466e-05, -7.02882337e-04,  3.98108202e-05,\n",
       "        9.43756511e-05, -1.02989258e-04,  8.89835760e-05,  6.01066319e-05,\n",
       "        1.12949822e-04,  4.54686926e-06,  2.09708566e-05, -3.21822156e-05,\n",
       "       -2.98380554e-06, -2.81939483e-04,  4.42136034e-05,  6.70094463e-04,\n",
       "        0.00000000e+00,  5.20491995e-07, -4.90471286e-02, -1.68953057e-01,\n",
       "        1.56248258e-01, -8.10587107e-01, -4.59107113e-01,  3.01593658e-01,\n",
       "        3.04598766e-02, -3.62815585e-01,  6.04173274e-02,  3.97642761e-01,\n",
       "       -1.92073154e-02,  3.96442360e-01,  8.26420131e-03,  1.07171201e+00,\n",
       "        1.55934472e-01, -4.64339624e-01, -4.27033435e-02, -6.45057640e-01,\n",
       "        1.02190939e-01, -7.91878865e-01,  6.29556340e-02, -1.22959712e-01,\n",
       "       -7.60431615e-03,  2.95122929e-02,  5.11887847e-01,  4.35752490e-02,\n",
       "       -6.87670187e-01, -9.25241666e-03,  6.99682898e-04, -1.23769446e+01,\n",
       "       -1.70720219e+01, -6.88134423e-01, -1.37412341e+00,  2.84527636e+01,\n",
       "       -5.79402958e+00,  1.19098300e+01,  1.56716127e+01,  1.63349942e+00,\n",
       "       -9.29357056e-01, -8.96045521e+00,  1.26392800e-01, -1.80436129e+00,\n",
       "        5.75827885e+00, -4.39995050e+00, -5.24156836e+00, -1.18967972e+01,\n",
       "       -3.44615719e+00, -1.15571681e+01, -1.00695699e+00, -5.20195396e+00,\n",
       "       -5.32345674e+00, -4.75067548e-01,  2.54129112e+01, -1.19064046e+00,\n",
       "       -1.17371738e+01,  9.39066550e-01, -9.44126473e-03, -1.19995751e+00,\n",
       "        4.26470250e-01, -2.24470661e+00,  6.47624921e+00,  1.13021353e+00,\n",
       "        8.91257465e+00,  1.66943607e+00, -1.36521100e+00, -6.70427531e-01,\n",
       "       -2.86972465e+00, -3.30954116e-01, -3.24714897e+00,  1.24469508e+00,\n",
       "        8.96789314e-01, -2.05015287e-01,  5.96160778e+00, -7.27749494e-01,\n",
       "        1.90551448e+00, -9.27570630e-02,  2.84374644e-01, -2.57448010e-01,\n",
       "       -1.44664255e-01,  1.19880033e+00, -1.33142783e-01, -8.33448579e+00,\n",
       "        9.98387944e-02,  1.90203855e-02,  3.91061545e+00,  7.55181400e+00,\n",
       "       -5.14769507e+00, -3.41561441e+00, -1.23309870e+01, -8.74178060e+00,\n",
       "        2.39198240e+00,  2.00772384e+00,  1.00217016e+00,  5.02202738e-01,\n",
       "        1.28793876e+01, -2.03225865e+00, -5.52949092e+00,  7.66633704e+00,\n",
       "        9.05356072e+00, -1.50547681e+00,  4.17217412e+00, -2.59435137e-01,\n",
       "        1.05721682e+00, -7.45026185e-02,  3.90909769e-01, -4.19594311e+00,\n",
       "       -2.87136810e-01, -1.20514788e+01, -9.52235034e-02, -2.19179782e-03,\n",
       "        3.49850686e+00,  4.23580408e-01, -3.70862163e+00, -1.04469574e+01,\n",
       "       -2.29091759e+00, -6.38415117e-01,  9.15912100e-01,  2.16407362e-02,\n",
       "        5.73089015e-01,  7.32890394e+00, -6.24645627e-01,  3.79967695e-01,\n",
       "        1.83081387e+00, -9.76511266e-01,  2.75707059e-02, -8.06742651e-01,\n",
       "       -1.24121704e-01, -9.60403958e-01, -8.59446892e-01,  8.35730193e-02,\n",
       "        8.83110074e-01, -3.88332363e-01,  6.14837644e+00,  9.40596732e-03,\n",
       "       -1.01540699e-02, -1.41113851e+01,  1.55227322e+00, -1.11424429e+01,\n",
       "       -1.17836557e+01, -1.44077250e+01, -3.36879414e-01,  9.25181877e+00,\n",
       "        1.50617934e-02,  1.25338361e+01,  1.55478724e+00,  1.71704341e+00,\n",
       "        2.33881297e+00,  1.60781447e+01, -1.32997812e+00, -1.10388357e+01,\n",
       "        9.55657841e-01, -1.34045398e+00,  2.23297364e+00,  1.39418834e-01,\n",
       "        6.68854143e+00, -1.12468034e+00, -3.91014164e+00, -2.67084447e-01,\n",
       "        5.13367676e-05,  3.55795719e+00,  3.57000161e+00,  2.11843535e-02,\n",
       "        2.73693547e+00,  4.14303094e-01,  8.06703823e-01,  1.77040764e-01,\n",
       "        5.30811982e-01, -1.15594326e+00, -1.22405579e-01, -1.11272729e+00,\n",
       "       -5.08795637e+00,  2.29259927e-02, -8.10688481e+00, -6.83894607e-01,\n",
       "       -1.51773348e+00,  1.46081215e+00, -6.44871040e-02,  6.69897070e+00,\n",
       "        6.86411050e-01,  1.20409516e+01,  3.10222403e-01, -2.73856919e-03,\n",
       "        2.08635419e+00,  3.60715999e+00, -8.45022166e+00, -5.17265534e-01,\n",
       "        4.87502669e-01,  1.66775725e-01, -5.85226426e+00, -3.29387067e+00,\n",
       "        1.31341522e+01,  9.25499170e-01,  4.99801004e-02,  4.40052376e+00,\n",
       "       -1.05091860e+01,  8.08191976e-03, -1.63854868e+00,  4.72157779e-01,\n",
       "       -9.91887717e-02,  6.81455050e+00,  8.66195146e-01,  2.18763271e+01,\n",
       "       -3.42711700e-02,  2.68952007e-04,  1.51417339e+00,  5.58004144e+00,\n",
       "       -4.78257470e-01,  8.08230651e-01, -3.06250530e-01, -1.39921236e+00,\n",
       "       -1.89736916e+00,  2.75847919e+00,  6.58636416e-01, -6.33928638e+00,\n",
       "        2.56223299e+00,  5.45523985e+00, -1.16095683e-01,  1.48317329e+00,\n",
       "        1.09148065e+00,  9.31286091e-02, -7.65083637e+00,  5.75429039e-01,\n",
       "        1.26090460e+00, -9.19578000e-02, -1.90553517e-03,  8.56801091e+00,\n",
       "       -1.03483764e+00,  1.79727464e+00, -1.04484765e-01, -5.14587526e+00,\n",
       "       -2.74082163e+00,  6.23973859e-01, -2.68057082e+00, -4.39063926e+00,\n",
       "        1.05480143e-01, -1.11324869e+01, -3.98917515e-01, -1.77982818e+00,\n",
       "       -1.11846423e+00,  1.28164565e-01,  1.13864945e+01,  7.79154601e-01,\n",
       "        1.42225031e+01,  3.42071234e-01, -1.06287454e-02,  6.40251528e-02,\n",
       "       -2.84525478e-01,  1.29299673e-02,  4.56294855e-01, -3.29686973e-02,\n",
       "       -7.07395199e-01, -3.08817560e-02,  7.79717743e-01, -1.31297971e-01,\n",
       "       -9.06991842e-02,  2.54198350e-02, -6.96958065e-02,  3.53614391e-02,\n",
       "       -2.41783764e-02,  4.57287850e-01,  5.93882528e-02,  8.35811388e-01,\n",
       "       -6.31662046e-03, -9.44983157e-04, -1.66912168e+00, -6.84425475e-02,\n",
       "       -7.31972454e+00,  1.80954944e+00,  4.55570541e-01,  3.91175065e-01,\n",
       "       -3.37242923e+00, -1.19872672e-01,  5.90538031e-01, -4.69115071e-01,\n",
       "       -6.44312853e-01, -1.73278681e+00, -2.98706821e-02,  1.92708298e+00,\n",
       "       -3.10293595e-01,  1.12676254e+01,  2.54296213e-01,  6.18550251e-03,\n",
       "        1.71798288e-02, -1.98631019e+00, -5.63236996e-02,  1.00680799e-03,\n",
       "       -1.64521118e-02,  1.62859079e+00, -1.81940146e-01, -1.61964583e-01,\n",
       "       -9.18229101e-02, -1.15291116e-01, -2.53345378e-01, -1.51853759e-02,\n",
       "        4.02816817e-01, -5.05214553e-03, -3.85956035e-01,  3.84739390e-02,\n",
       "        1.45641936e-04, -3.79835300e+00, -4.22707469e+00, -5.57283173e+00,\n",
       "        4.58784197e+00,  2.29939902e+01, -4.77013023e+00,  3.54176224e+01,\n",
       "        2.59079102e+00,  7.81232279e+00,  3.34513689e+00,  3.65614179e-01,\n",
       "       -2.70021591e+01, -1.11412536e+00, -6.02461740e+01, -1.41706435e+00,\n",
       "       -6.64452313e-03, -2.85638434e-01,  5.83863369e-02, -2.14740957e-02,\n",
       "        3.67244494e+00,  1.34826114e+00,  1.20994811e+00, -1.87857476e-01,\n",
       "        6.41026213e-01, -3.01550517e-01,  8.79677079e-04, -2.94759206e+00,\n",
       "       -1.05263994e-01, -1.28156783e-01,  8.01065922e-02,  3.55155499e-04,\n",
       "       -1.45934779e+00, -2.81251556e+00, -7.56325985e+00,  2.80795720e+00,\n",
       "        2.53487387e-01, -4.40094094e-01,  8.31340978e-02, -1.40931143e-01,\n",
       "        1.48818039e-01, -4.66798793e+00, -8.51940341e-01,  1.81936126e+01,\n",
       "        1.90236456e-01,  2.10249469e-02, -1.04220052e-01, -8.71300476e-01,\n",
       "       -1.10818504e+00,  6.28430068e-01,  4.73681438e-01,  2.13120493e-01,\n",
       "       -1.30417736e+00,  3.94536323e-02, -1.41798396e+00, -2.88414741e-01,\n",
       "       -4.23513343e+00, -2.07763522e-01, -8.96689412e-05, -5.50846510e+00,\n",
       "       -4.14302034e+00,  2.98149262e+00, -5.82048428e-01, -6.26638008e-01,\n",
       "        2.12947695e+00, -2.29721593e-01, -3.47263206e+00,  1.14781010e+00,\n",
       "        1.02184755e+01,  1.78961646e-01,  9.00186576e-03, -4.35043772e-01,\n",
       "       -3.69796288e+00, -7.62624457e-02, -7.53635908e-01,  2.61513529e-01,\n",
       "       -6.27462063e-02,  3.70316039e+00,  2.66291067e-01,  6.47532329e+00,\n",
       "        1.21098845e-01,  1.43236951e-03, -1.39647396e+00, -2.36452901e-01,\n",
       "       -3.97121399e-01,  1.32405653e-01, -9.97636238e-02,  2.93820586e+00,\n",
       "        5.23468881e-01, -1.63209299e+00,  2.27771645e-01, -1.15728779e-02,\n",
       "        6.25459910e-03,  1.49568142e-02,  2.14068172e-01,  1.26890813e-02,\n",
       "        9.17025214e-01, -2.32506116e-01, -3.72597720e+00,  9.21785757e-03,\n",
       "        1.64338498e-03, -7.14967042e-02, -4.20014802e-02,  1.37646672e-02,\n",
       "        1.27598672e+00,  6.59640407e-02,  1.38391028e-01,  4.25543069e-02,\n",
       "       -2.13398809e-03, -5.46939022e-01,  7.64202049e-02,  2.59569215e+00,\n",
       "       -3.74251076e-01, -8.85098335e+00, -6.48380063e-02, -3.95983193e-03,\n",
       "       -4.23295998e-03,  8.48212489e-02,  1.85469198e-04, -3.96845404e-01,\n",
       "       -5.86779037e-03, -1.87559374e-05, -2.72914703e+00, -4.08380125e-01,\n",
       "       -8.05753810e+00, -5.68511318e-01,  2.30795738e-03,  6.25136467e-02,\n",
       "        2.19443319e+00,  8.92572386e-02, -1.96430940e-04, -1.45539705e+00,\n",
       "        1.35095941e+00, -9.30255241e-03,  0.00000000e+00, -5.14709207e-04,\n",
       "       -1.35141761e-04])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polynomial_regression_ridge = Ridge(alpha=ridge_optimal_for_polynomial_regression.best_params_['alpha']).fit(PolynomialFeatures(power).fit_transform(X_train), y_train)\n",
    "y_predicted = polynomial_regression_ridge.predict(PolynomialFeatures(power).fit_transform(X_test))\n",
    "polynomial_regression_ridge_errors = {'MAE': mean_absolute_error(y_predicted, y_test),\n",
    "                                      'RMSE': mean_squared_error(y_predicted, y_test),\n",
    "                                      'MSE': mean_squared_error(y_predicted, y_test)**0.5,\n",
    "                                      'MAPE': mean_absolute_percentage_error(y_predicted, y_test),\n",
    "                                      'R^2': polynomial_regression_ridge.score(PolynomialFeatures(power).fit_transform(X_test), y_test)}\n",
    "print(f\"MAE: {mean_absolute_error(y_predicted, y_test)}\",\n",
    "      f'RMSE: {mean_squared_error(y_predicted, y_test)}',\n",
    "      f'MSE: {mean_squared_error(y_predicted, y_test)**0.5}',\n",
    "      f'MAPE: {mean_absolute_percentage_error(y_predicted, y_test)}',\n",
    "      f'R^2: {polynomial_regression_ridge.score(PolynomialFeatures(power).fit_transform(X_test), y_test)}',\n",
    "      sep='\\n')\n",
    "polynomial_regression_ridge.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso (Полиномиальная регрессия + L1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso (полиномиальная регрессия) - обучение с подобранным гиппер параметрам $\\alpha$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.891e+07, tolerance: 7.908e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.945e+07, tolerance: 8.028e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.045e+07, tolerance: 8.260e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.971e+07, tolerance: 8.096e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.957e+07, tolerance: 8.088e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.919e+07, tolerance: 7.908e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.969e+07, tolerance: 8.028e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.073e+07, tolerance: 8.260e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.000e+07, tolerance: 8.096e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.984e+07, tolerance: 8.088e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.724e+07, tolerance: 1.010e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_optimal_for_polynomial_regression = GridSearchCV(Lasso(), {'alpha': np.arange(1, 3, 1)}).fit(PolynomialFeatures(power).fit_transform(X_train), y_train)\n",
    "lasso_optimal_for_polynomial_regression.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.891e+07, tolerance: 7.908e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.945e+07, tolerance: 8.028e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.045e+07, tolerance: 8.260e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.971e+07, tolerance: 8.096e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.957e+07, tolerance: 8.088e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.919e+07, tolerance: 7.908e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.969e+07, tolerance: 8.028e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.073e+07, tolerance: 8.260e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.000e+07, tolerance: 8.096e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.984e+07, tolerance: 8.088e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.724e+07, tolerance: 1.010e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.891e+07, tolerance: 7.908e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.945e+07, tolerance: 8.028e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.045e+07, tolerance: 8.260e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.971e+07, tolerance: 8.096e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.957e+07, tolerance: 8.088e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.919e+07, tolerance: 7.908e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.969e+07, tolerance: 8.028e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.073e+07, tolerance: 8.260e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.000e+07, tolerance: 8.096e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.984e+07, tolerance: 8.088e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.724e+07, tolerance: 1.010e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.891e+07, tolerance: 7.908e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.945e+07, tolerance: 8.028e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.045e+07, tolerance: 8.260e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.971e+07, tolerance: 8.096e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.957e+07, tolerance: 8.088e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.919e+07, tolerance: 7.908e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.969e+07, tolerance: 8.028e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.073e+07, tolerance: 8.260e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.000e+07, tolerance: 8.096e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.984e+07, tolerance: 8.088e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.724e+07, tolerance: 1.010e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.891e+07, tolerance: 7.908e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.945e+07, tolerance: 8.028e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.045e+07, tolerance: 8.260e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.971e+07, tolerance: 8.096e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.957e+07, tolerance: 8.088e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.919e+07, tolerance: 7.908e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.969e+07, tolerance: 8.028e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.073e+07, tolerance: 8.260e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.000e+07, tolerance: 8.096e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.984e+07, tolerance: 8.088e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.724e+07, tolerance: 1.010e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.891e+07, tolerance: 7.908e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.945e+07, tolerance: 8.028e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.045e+07, tolerance: 8.260e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.971e+07, tolerance: 8.096e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.957e+07, tolerance: 8.088e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.919e+07, tolerance: 7.908e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.969e+07, tolerance: 8.028e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.073e+07, tolerance: 8.260e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.000e+07, tolerance: 8.096e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.984e+07, tolerance: 8.088e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.724e+07, tolerance: 1.010e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 1}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 10\n",
    "a = 0\n",
    "b = 1000\n",
    "while i > 0.0001:\n",
    "    lasso_optimal_for_polynomial_regression = GridSearchCV(Lasso(), {'alpha': np.arange(1, 3, 1)}).fit(PolynomialFeatures(power).fit_transform(X_train), y_train)\n",
    "    if (lasso_optimal_for_polynomial_regression.best_params_['alpha'] == 0):\n",
    "        break\n",
    "    elif (lasso_optimal_for_polynomial_regression.best_params_['alpha'] != b):\n",
    "        a = lasso_optimal_for_polynomial_regression.best_params_['alpha']-i\n",
    "        b = lasso_optimal_for_polynomial_regression.best_params_['alpha']+i\n",
    "        i/=10\n",
    "    else:\n",
    "        a = b\n",
    "        b*=2\n",
    "\n",
    "lasso_optimal_for_polynomial_regression.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso (полиномиальная регрессия) - обучение с подобранным гиппер параметрам $\\alpha$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mike\\Desktop\\4semak\\Maching_learning\\Maching_Learning\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=6.00373e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 50.279316396787124\n",
      "RMSE: 7092.091908509631\n",
      "MSE: 84.21455876812293\n",
      "MAPE: 1.059882059673164\n",
      "R^2: 0.2998812063016326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00, -4.58928995e-06,  4.69207058e-04,  5.00378961e-05,\n",
       "       -4.90849537e-05,  4.28608457e-06, -1.33816406e-04,  1.54211834e-04,\n",
       "       -1.67013015e-05, -4.57088201e-05,  1.71559733e-04, -3.20628301e-06,\n",
       "        1.25866078e-04,  1.82867051e-05, -7.08125242e-04,  4.02343143e-05,\n",
       "        9.50832920e-05, -1.03219530e-04,  9.36978427e-05,  6.03120450e-05,\n",
       "        1.13891284e-04,  4.79077146e-06,  2.05123108e-05, -3.19327909e-05,\n",
       "       -3.02736535e-06, -2.83279748e-04,  4.41967974e-05,  6.65816899e-04,\n",
       "        0.00000000e+00,  1.00189691e-05, -4.90525002e-02, -1.72496333e-01,\n",
       "        1.55784648e-01, -8.06300078e-01, -4.57411474e-01,  3.02606566e-01,\n",
       "        3.03726639e-02, -3.63732745e-01,  5.95669858e-02,  3.96695680e-01,\n",
       "       -1.92738909e-02,  3.95795357e-01,  8.30768302e-03,  1.07355893e+00,\n",
       "        1.55758783e-01, -4.64614345e-01, -4.22612023e-02, -6.44322406e-01,\n",
       "        1.01532795e-01, -7.91089860e-01,  6.29134517e-02, -1.22990586e-01,\n",
       "       -7.59016743e-03,  2.94839429e-02,  5.11971784e-01,  4.35996989e-02,\n",
       "       -6.90630869e-01, -9.25002579e-03,  6.99296264e-04, -1.26030589e+01,\n",
       "       -1.71262483e+01, -6.18975258e-01, -1.35706793e+00,  2.87471862e+01,\n",
       "       -5.87747290e+00,  1.21060576e+01,  1.57137136e+01,  1.76457786e+00,\n",
       "       -9.31738426e-01, -8.97216802e+00,  1.30514547e-01, -1.91236309e+00,\n",
       "        5.77861479e+00, -4.30861618e+00, -5.26979739e+00, -1.20424474e+01,\n",
       "       -3.44496510e+00, -1.19508519e+01, -1.01043601e+00, -5.29198968e+00,\n",
       "       -5.34624244e+00, -4.72830066e-01,  2.58777655e+01, -1.20049649e+00,\n",
       "       -1.19832038e+01,  9.45864908e-01, -9.47895467e-03, -1.20189649e+00,\n",
       "        4.10703506e-01, -2.25079996e+00,  6.51884188e+00,  1.12815738e+00,\n",
       "        8.96419361e+00,  1.67735433e+00, -1.34072851e+00, -6.71962144e-01,\n",
       "       -2.85067985e+00, -3.28041921e-01, -3.26316358e+00,  1.24894741e+00,\n",
       "        9.09500117e-01, -2.16191670e-01,  5.91612394e+00, -7.28766226e-01,\n",
       "        1.86349645e+00, -9.38331223e-02,  2.78138135e-01, -2.57077247e-01,\n",
       "       -1.44040215e-01,  1.23039081e+00, -1.33213297e-01, -8.31522731e+00,\n",
       "        1.00647840e-01,  1.90590285e-02,  3.97845695e+00,  7.60744547e+00,\n",
       "       -5.27354977e+00, -3.38668365e+00, -1.25091662e+01, -8.80791924e+00,\n",
       "        2.36708293e+00,  2.00731102e+00,  9.60013352e-01,  4.92049373e-01,\n",
       "        1.29351652e+01, -2.03143743e+00, -5.59147717e+00,  7.69486606e+00,\n",
       "        9.25471779e+00, -1.50769708e+00,  4.46222579e+00, -2.58100072e-01,\n",
       "        1.11755956e+00, -8.22254724e-02,  3.86665588e-01, -4.46772761e+00,\n",
       "       -2.87439690e-01, -1.22557573e+01, -9.89167383e-02, -2.19694173e-03,\n",
       "        3.50652723e+00,  3.79314514e-01, -3.70660498e+00, -1.05338446e+01,\n",
       "       -2.29990242e+00, -6.67817433e-01,  9.17631574e-01, -4.79378889e-03,\n",
       "        5.70299549e-01,  7.38420001e+00, -6.27000312e-01,  3.53192893e-01,\n",
       "        1.84533333e+00, -8.97286069e-01,  2.44926112e-02, -7.35308178e-01,\n",
       "       -1.23662424e-01, -9.50102057e-01, -8.68074481e-01,  8.22210526e-02,\n",
       "        8.29309741e-01, -3.89050394e-01,  6.09157141e+00,  8.57392577e-03,\n",
       "       -1.01763843e-02, -1.41651770e+01,  1.59660948e+00, -1.11876008e+01,\n",
       "       -1.17970921e+01, -1.45923745e+01, -3.33200768e-01,  9.28837974e+00,\n",
       "        1.41740792e-02,  1.25913559e+01,  1.55040431e+00,  1.67080052e+00,\n",
       "        2.35678141e+00,  1.62034040e+01, -1.35553906e+00, -1.10635466e+01,\n",
       "        9.60259937e-01, -1.33381665e+00,  2.23951838e+00,  1.40770434e-01,\n",
       "        6.67538558e+00, -1.12736902e+00, -3.79692593e+00, -2.69446322e-01,\n",
       "        8.58804052e-05,  3.55052578e+00,  3.58847126e+00,  2.06912213e-02,\n",
       "        2.75442154e+00,  4.15431790e-01,  8.03119906e-01,  1.78013417e-01,\n",
       "        4.96803891e-01, -1.15472012e+00, -8.39250964e-02, -1.12148884e+00,\n",
       "       -5.10531817e+00,  3.05518457e-02, -8.10163458e+00, -6.84790855e-01,\n",
       "       -1.51841661e+00,  1.46667395e+00, -6.42273439e-02,  6.70156431e+00,\n",
       "        6.84782201e-01,  1.20067657e+01,  3.10719120e-01, -2.76092523e-03,\n",
       "        2.08482402e+00,  3.63406723e+00, -8.45531229e+00, -5.14914227e-01,\n",
       "        5.18027362e-01,  1.70416906e-01, -5.86407683e+00, -3.29464319e+00,\n",
       "        1.31806964e+01,  9.16292285e-01, -8.16850056e-02,  4.43196969e+00,\n",
       "       -1.05688446e+01,  6.48824666e-03, -1.64741804e+00,  4.77272354e-01,\n",
       "       -9.79674343e-02,  6.82309727e+00,  8.79370399e-01,  2.22426536e+01,\n",
       "       -3.35472816e-02,  2.83843812e-04,  1.52256805e+00,  5.60309344e+00,\n",
       "       -4.78657620e-01,  8.08926487e-01, -3.08624405e-01, -1.44688875e+00,\n",
       "       -1.90183446e+00,  2.76618678e+00,  6.59743055e-01, -6.31318913e+00,\n",
       "        2.55871904e+00,  5.52203806e+00, -1.16006750e-01,  1.49773383e+00,\n",
       "        1.09506946e+00,  9.35006092e-02, -7.71871386e+00,  5.74497110e-01,\n",
       "        1.20934936e+00, -9.27033675e-02, -1.92196594e-03,  8.59776566e+00,\n",
       "       -1.03911324e+00,  1.80256359e+00, -1.00428421e-01, -5.14914341e+00,\n",
       "       -2.75795515e+00,  6.09252430e-01, -2.68020183e+00, -4.44771413e+00,\n",
       "        1.12447925e-01, -1.12271124e+01, -4.05674732e-01, -1.79968764e+00,\n",
       "       -1.10295178e+00,  1.28585613e-01,  1.14599687e+01,  7.88606142e-01,\n",
       "        1.45373073e+01,  3.45548783e-01, -1.06638329e-02,  6.42968195e-02,\n",
       "       -2.82538078e-01,  1.30727462e-02,  4.60040257e-01, -3.34829006e-02,\n",
       "       -7.07861154e-01, -3.01565630e-02,  7.79074573e-01, -1.31705957e-01,\n",
       "       -9.13196522e-02,  2.55573720e-02, -6.97477038e-02,  3.49045724e-02,\n",
       "       -2.42024760e-02,  4.55950507e-01,  5.93840612e-02,  8.33092466e-01,\n",
       "       -6.41963889e-03, -9.42174698e-04, -1.66477711e+00, -6.60659915e-02,\n",
       "       -7.41782026e+00,  1.82317876e+00,  5.05127664e-01,  3.76477677e-01,\n",
       "       -3.34880241e+00, -1.19297745e-01,  5.51448503e-01, -4.67574994e-01,\n",
       "       -6.52718856e-01, -1.73302419e+00, -2.93926899e-02,  1.96293399e+00,\n",
       "       -3.09709091e-01,  1.12927549e+01,  2.54195853e-01,  6.17920658e-03,\n",
       "        1.72158738e-02, -2.00993700e+00, -5.35067599e-02,  9.14063129e-03,\n",
       "       -1.79023905e-02,  1.64475157e+00, -1.81976943e-01, -1.57826583e-01,\n",
       "       -9.14069871e-02, -1.14315077e-01, -2.53955799e-01, -1.51386171e-02,\n",
       "        3.95636644e-01, -5.10135637e-03, -3.87281031e-01,  3.82560396e-02,\n",
       "        1.46860317e-04, -3.97171902e+00, -4.19253859e+00, -5.52661608e+00,\n",
       "        4.59745014e+00,  2.37454564e+01, -4.82364565e+00,  3.61552509e+01,\n",
       "        2.60021941e+00,  7.95829036e+00,  3.34003232e+00,  3.65628587e-01,\n",
       "       -2.76216485e+01, -1.14746814e+00, -6.15552954e+01, -1.42783288e+00,\n",
       "       -6.67735528e-03, -2.88463868e-01,  4.29142112e-02, -2.44690396e-02,\n",
       "        3.60590739e+00,  1.35884811e+00,  1.15485925e+00, -1.88077799e-01,\n",
       "        6.30251736e-01, -3.00257222e-01,  1.42045597e-03, -2.90623792e+00,\n",
       "       -1.02242941e-01,  1.18443743e-02,  8.08089347e-02,  3.53204402e-04,\n",
       "       -1.45437103e+00, -2.83967400e+00, -7.84124631e+00,  2.85301225e+00,\n",
       "        1.24551861e-01, -4.40549486e-01,  6.19866393e-02, -1.34150475e-01,\n",
       "        1.48087546e-01, -4.59553000e+00, -8.40111533e-01,  1.86859082e+01,\n",
       "        1.91564768e-01,  2.10513848e-02, -1.00492454e-01, -8.27172187e-01,\n",
       "       -1.11797567e+00,  6.46072161e-01,  4.73946916e-01,  2.16036273e-01,\n",
       "       -1.30349333e+00,  3.94396738e-02, -1.42031061e+00, -2.89663174e-01,\n",
       "       -4.31316349e+00, -2.07981069e-01, -8.04698663e-05, -5.90356129e+00,\n",
       "       -4.15579114e+00,  2.54721108e+00, -5.93862637e-01, -7.21474899e-01,\n",
       "        2.11803476e+00, -2.29826802e-01, -3.06232549e+00,  1.16567438e+00,\n",
       "        1.10224818e+01,  1.88966819e-01,  9.06771952e-03, -4.29285432e-01,\n",
       "       -3.72715350e+00, -7.55317725e-02, -7.60120996e-01,  2.60499607e-01,\n",
       "       -6.33496395e-02,  3.72770656e+00,  2.66436468e-01,  6.49068290e+00,\n",
       "        1.21005235e-01,  1.42564705e-03, -1.29555322e+00, -2.47695112e-01,\n",
       "       -3.47187047e-01,  1.14078076e-01, -9.99336529e-02,  2.74439517e+00,\n",
       "        5.30199388e-01, -1.30017011e+00,  2.29590066e-01, -1.12248996e-02,\n",
       "        6.41393967e-03,  1.27313936e-02,  2.13645767e-01,  1.27817596e-02,\n",
       "        9.27665434e-01, -2.32144041e-01, -3.71353235e+00,  9.25430073e-03,\n",
       "        1.64818013e-03, -6.54991628e-02, -4.39054368e-02,  1.36570726e-02,\n",
       "        1.23017677e+00,  6.73328190e-02,  2.02119899e-01,  4.28683960e-02,\n",
       "       -2.07026745e-03, -5.44049295e-01,  7.65717355e-02,  2.61235827e+00,\n",
       "       -3.74158575e-01, -8.83471637e+00, -6.44825540e-02, -3.94687998e-03,\n",
       "       -4.24529078e-03,  8.45479549e-02,  1.55831609e-04, -3.97006845e-01,\n",
       "       -5.89648675e-03, -1.93588252e-05, -2.63653680e+00, -4.16535370e-01,\n",
       "       -8.43544652e+00, -5.70448102e-01,  1.96520639e-03,  6.21516629e-02,\n",
       "        2.18549465e+00,  8.90582591e-02, -1.97073062e-04, -1.78607948e+00,\n",
       "        1.34224281e+00, -9.34590438e-03,  0.00000000e+00, -5.19554406e-04,\n",
       "       -1.35191691e-04])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polynomial_regression_lasso = Ridge(alpha=lasso_optimal_for_polynomial_regression.best_params_['alpha']).fit(PolynomialFeatures(power).fit_transform(X_train), y_train)\n",
    "y_predicted = polynomial_regression_lasso.predict(PolynomialFeatures(power).fit_transform(X_test))\n",
    "polynomial_regression_lasso_errors = {'MAE': mean_absolute_error(y_predicted, y_test),\n",
    "                                      'RMSE': mean_squared_error(y_predicted, y_test),\n",
    "                                      'MSE': mean_squared_error(y_predicted, y_test)**0.5,\n",
    "                                      'MAPE': mean_absolute_percentage_error(y_predicted, y_test),\n",
    "                                      'R^2': polynomial_regression_lasso.score(PolynomialFeatures(power).fit_transform(X_test), y_test)}\n",
    "print(f\"MAE: {mean_absolute_error(y_predicted, y_test)}\",\n",
    "      f'RMSE: {mean_squared_error(y_predicted, y_test)}',\n",
    "      f'MSE: {mean_squared_error(y_predicted, y_test)**0.5}',\n",
    "      f'MAPE: {mean_absolute_percentage_error(y_predicted, y_test)}',\n",
    "      f'R^2: {polynomial_regression_lasso.score(PolynomialFeatures(power).fit_transform(X_test), y_test)}',\n",
    "      sep='\\n')\n",
    "polynomial_regression_lasso.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../Pipelines/Laba1/PolynomialRegressions/PolynomialRegressionLassoModel__cleared.sav']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(polynomial_regression_classic, '../../Pipelines/Laba1/PolynomialRegressions/PolynomialRegressionClassicModel__cleared.sav')\n",
    "joblib.dump(polynomial_regression_ridge,\n",
    "            '../../Pipelines/Laba1/PolynomialRegressions/PolynomialRegressionRidgeModel__cleared.sav')\n",
    "joblib.dump(polynomial_regression_lasso,\n",
    "            '../../Pipelines/Laba1/PolynomialRegressions/PolynomialRegressionLassoModel__cleared.sav')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Maching_Learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "72fa092132459f2e9e0e62acfe6b07e699dc0f19c1369114b8b6fdbd4fdea11c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
